{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_PATH_SIMILARITY = {\n",
    "    'bert': {\n",
    "        'model': 'v36/similarity/bert-base-similarity.pb',\n",
    "        'vocab': 'tokenizer/sp10m.cased.bert.vocab',\n",
    "        'tokenizer': 'tokenizer/sp10m.cased.bert.model',\n",
    "    },\n",
    "    'tiny-bert': {\n",
    "        'model': 'v36/similarity/tiny-bert-similarity.pb',\n",
    "        'vocab': 'tokenizer/sp10m.cased.bert.vocab',\n",
    "        'tokenizer': 'tokenizer/sp10m.cased.bert.model',\n",
    "    },\n",
    "    'albert': {\n",
    "        'model': 'v36/similarity/albert-base-similarity.pb',\n",
    "        'vocab': 'tokenizer/sp10m.cased.v10.vocab',\n",
    "        'tokenizer': 'tokenizer/sp10m.cased.v10.model',\n",
    "    },\n",
    "    'tiny-albert': {\n",
    "        'model': 'v36/similarity/albert-tiny-similarity.pb',\n",
    "        'vocab': 'tokenizer/sp10m.cased.v10.vocab',\n",
    "        'tokenizer': 'tokenizer/sp10m.cased.v10.model',\n",
    "    },\n",
    "    'xlnet': {\n",
    "        'model': 'v36/similarity/xlnet-base-similarity.pb',\n",
    "        'vocab': 'tokenizer/sp10m.cased.v9.vocab',\n",
    "        'tokenizer': 'tokenizer/sp10m.cased.v9.model',\n",
    "    },\n",
    "    'alxlnet': {\n",
    "        'model': 'v36/similarity/alxlnet-base-similarity.pb',\n",
    "        'vocab': 'tokenizer/sp10m.cased.v9.vocab',\n",
    "        'tokenizer': 'tokenizer/sp10m.cased.v9.model',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\n",
      "tiny-bert\n",
      "albert\n",
      "tiny-albert\n",
      "xlnet\n",
      "alxlnet\n"
     ]
    }
   ],
   "source": [
    "for k in S3_PATH_SIMILARITY.keys():\n",
    "    if k != 'multinomial':\n",
    "        print(k)\n",
    "        os.system(f\"wget https://f000.backblazeb2.com/file/malaya-model/{S3_PATH_SIMILARITY[k]['model']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.tools.graph_transforms import TransformGraph\n",
    "from glob import glob\n",
    "tf.compat.v1.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.compat.v1.gfile.GFile('tiny-bert-similarity.pb', \"rb\") as f:\n",
    "#     graph_def = tf.compat.v1.GraphDef()\n",
    "#     graph_def.ParseFromString(f.read())\n",
    "\n",
    "# with tf.compat.v1.Graph().as_default() as graph:\n",
    "#     tf.compat.v1.import_graph_def(graph_def)\n",
    "\n",
    "# op = graph.get_operations()\n",
    "# x = []\n",
    "# for i in op:\n",
    "#     try:\n",
    "#         if i.values()[0].shape[-1] == 312:\n",
    "#         #if 'import/bert/encoder/layer_11/output/LayerNorm/batchnorm/add' in i.values()[0].name:\n",
    "#             x.append(i.values())\n",
    "#     except Exception as e:\n",
    "#         pass\n",
    "    \n",
    "# x[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'albert-base-similarity.pb': 'import/bert/encoder/transformer/group_0_11/layer_11/inner_group_0/LayerNorm_1/batchnorm/add_1:0',\n",
    "          'albert-tiny-similarity.pb': 'import/bert/encoder/transformer/group_0_3/layer_3/inner_group_0/LayerNorm_1/batchnorm/add_1:0',\n",
    "          'bert-base-similarity.pb': 'import/bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1:0',\n",
    "          'tiny-bert-similarity.pb': 'import/bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0',\n",
    "          'xlnet-base-similarity.pb': 'import/model/transformer/layer_11/ff/LayerNorm/batchnorm/add_1:0',\n",
    "          'alxlnet-base-similarity.pb': 'import/model/transformer/layer_shared_11/ff/LayerNorm/batchnorm/add_1:0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['albert-tiny-similarity.pb',\n",
       " 'xlnet-base-similarity.pb',\n",
       " 'albert-base-similarity.pb',\n",
       " 'bert-base-similarity.pb',\n",
       " 'alxlnet-base-similarity.pb',\n",
       " 'tiny-bert-similarity.pb']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbs = glob('*.pb')\n",
    "pbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-9f7922d092f8>:11: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.gfile.GFile.\n",
      "albert-tiny-similarity.pb ['Placeholder', 'Placeholder_1', 'Placeholder_2']\n",
      "xlnet-base-similarity.pb ['Placeholder', 'Placeholder_1', 'Placeholder_2']\n",
      "albert-base-similarity.pb ['Placeholder', 'Placeholder_1', 'Placeholder_2']\n",
      "bert-base-similarity.pb ['Placeholder', 'Placeholder_1', 'Placeholder_2']\n",
      "alxlnet-base-similarity.pb ['Placeholder', 'Placeholder_1', 'Placeholder_2']\n",
      "tiny-bert-similarity.pb ['Placeholder', 'Placeholder_1', 'Placeholder_2']\n"
     ]
    }
   ],
   "source": [
    "transforms = ['add_default_attributes',\n",
    "             'remove_nodes(op=Identity, op=CheckNumerics, op=Dropout)',\n",
    "             'fold_batch_norms',\n",
    "             'fold_old_batch_norms',\n",
    "             'quantize_weights(fallback_min=-10, fallback_max=10)',\n",
    "             'strip_unused_nodes',\n",
    "             'sort_by_execution_order']\n",
    "\n",
    "for pb in pbs:\n",
    "    input_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.compat.v1.gfile.FastGFile(pb, 'rb') as f:\n",
    "        input_graph_def.ParseFromString(f.read())\n",
    "        \n",
    "    inputs = ['Placeholder', 'Placeholder_1', 'Placeholder_2']\n",
    "    \n",
    "    if 'bert' in pb:\n",
    "        outputs = ['logits', 'bert/pooler/dense/BiasAdd']\n",
    "        \n",
    "    if 'xlnet'in pb:\n",
    "        outputs = ['logits', 'model_1/sequnece_summary/summary/BiasAdd']\n",
    "        \n",
    "    a = [mapping[pb].replace('import/','').replace(':0','')]\n",
    "        \n",
    "    print(pb, inputs)\n",
    "    \n",
    "    transformed_graph_def = TransformGraph(input_graph_def, \n",
    "                                           inputs,\n",
    "                                           outputs + a, transforms)\n",
    "    \n",
    "    with tf.compat.v1.gfile.GFile(f'{pb}.quantized', 'wb') as f:\n",
    "        f.write(transformed_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename, **kwargs):\n",
    "    with tf.compat.v1.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # https://github.com/onnx/tensorflow-onnx/issues/77#issuecomment-445066091\n",
    "    # to fix import T5\n",
    "    for node in graph_def.node:\n",
    "        if node.op == 'RefSwitch':\n",
    "            node.op = 'Switch'\n",
    "            for index in xrange(len(node.input)):\n",
    "                if 'moving_' in node.input[index]:\n",
    "                    node.input[index] = node.input[index] + '/read'\n",
    "        elif node.op == 'AssignSub':\n",
    "            node.op = 'Sub'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "        elif node.op == 'AssignAdd':\n",
    "            node.op = 'Add'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "        elif node.op == 'Assign':\n",
    "            node.op = 'Identity'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "            if 'validate_shape' in node.attr:\n",
    "                del node.attr['validate_shape']\n",
    "            if len(node.input) == 2:\n",
    "                node.input[0] = node.input[1]\n",
    "                del node.input[1]\n",
    "\n",
    "    with tf.compat.v1.Graph().as_default() as graph:\n",
    "        tf.compat.v1.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('tiny-bert-similarity.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "segment_ids = g.get_tensor_by_name('import/Placeholder_1:0')\n",
    "input_masks = g.get_tensor_by_name('import/Placeholder_2:0')\n",
    "logits = g.get_tensor_by_name(mapping['tiny-bert-similarity.pb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.compat.v1.Tensor 'import/bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0' shape=(?, 312) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sess = tf.compat.v1.InteractiveSession(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/malaya/function/__init__.py:50: The name tf.compat.v1.ConfigProto is deprecated. Please use @@#ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import malaya\n",
    "\n",
    "model = malaya.similarity.transformer(model = 'alxlnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaya.text.bpe import xlnet_tokenization\n",
    "import numpy as np\n",
    "\n",
    "r = xlnet_tokenization(model._tokenizer, ['benci', 'suka', 'hodoh la', 'sakai bodoh la la la la'])\n",
    "batch_x = r[0]\n",
    "batch_mask = r[1]\n",
    "batch_segment = np.array(r[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 2, 4, 4, 4, 4, 4, 4],\n",
       "       [1, 1, 2, 4, 4, 4, 4, 4, 4],\n",
       "       [1, 1, 1, 2, 4, 4, 4, 4, 4],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_segment[batch_segment == 0 ] = 1\n",
    "batch_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(batch_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 70 ms, sys: 4.86 ms, total: 74.9 ms\n",
      "Wall time: 15.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36, 312)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "l = test_sess.run(logits, feed_dict = {x: batch_x,\n",
    "                                  segment_ids: batch_segment,\n",
    "                                  input_masks: batch_mask})\n",
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9, 312)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.reshape((*np.array(batch_x).shape,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "l = test_sess.run(logits, feed_dict = {x: batch_x,\n",
    "                                  segment_ids: batch_segment,\n",
    "                                  input_masks: batch_mask})\n",
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, x_len, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# test_sess.run(logits, feed_dict = {x: [[1,2,3,3,4]], x_len: [[1,1,1,1,1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# test_sess.run(logits, feed_dict = {x: [[1,2,3,3,4]], x_len: [[1,1,1,1,1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['albert-base-similarity.pb.quantized',\n",
       " 'albert-tiny-similarity.pb.quantized',\n",
       " 'bert-base-similarity.pb.quantized',\n",
       " 'xlnet-base-similarity.pb.quantized',\n",
       " 'tiny-bert-similarity.pb.quantized',\n",
       " 'alxlnet-base-similarity.pb.quantized']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized = glob('*.pb.quantized')\n",
    "quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm *.pb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter = @@#lite.TFLiteConverter.from_frozen_graph(\n",
    "#     graph_def_file='test.pb',\n",
    "#     input_arrays=['Placeholder', 'Placeholder_1'],\n",
    "#     input_shapes={'Placeholder' : [None, 512], 'Placeholder_1': [None, 512]},\n",
    "#     output_arrays=['logits'],\n",
    "# )\n",
    "# # converter.allow_custom_ops=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter.target_spec.supported_ops = [tf.compat.v1.lite.OpsSet.TFLITE_BUILTINS, tf.compat.v1.lite.OpsSet.SELECT_TF_OPS]\n",
    "# converter.target_spec.supported_types = [tf.compat.v1.float16]\n",
    "# converter.optimizations = [tf.compat.v1.lite.Optimize.DEFAULT]\n",
    "# converter.experimental_new_converter = True\n",
    "# tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter.target_spec.supported_ops = [tf.compat.v1.lite.OpsSet.TFLITE_BUILTINS, \n",
    "#                                        tf.compat.v1.lite.OpsSet.SELECT_TF_OPS]\n",
    "# converter.target_spec.supported_types = [tf.compat.v1.float16]\n",
    "# converter.optimizations = [tf.compat.v1.lite.Optimize.DEFAULT]\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# with open('tiny-bert-sentiment-float16.tflite', 'wb') as f:\n",
    "#     f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter.target_spec.supported_ops = [tf.compat.v1.lite.OpsSet.TFLITE_BUILTINS, \n",
    "#                                        tf.compat.v1.lite.OpsSet.SELECT_TF_OPS]\n",
    "# converter.optimizations = [tf.compat.v1.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# with open('tiny-bert-sentiment-hybrid.tflite', 'wb') as f:\n",
    "#     f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpreter = tf.compat.v1.lite.Interpreter(model_path='tiny-bert-sentiment-hybrid.tflite')\n",
    "# interpreter.allocate_tensors()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
